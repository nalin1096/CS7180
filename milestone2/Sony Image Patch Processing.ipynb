{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Need to better understand how patch processing is\n",
    "work when the LSD model is trained using images from\n",
    "the Sony camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import rawpy\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"dataset/sample/\"\n",
    "\n",
    "input_dir = base_dir + 'short/'\n",
    "gt_dir = base_dir + 'long/'\n",
    "\n",
    "# Patch size\n",
    "\n",
    "ps = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels                                                              \n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level                      \n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train IDs                                                                                   \n",
    "train_fns = glob.glob(gt_dir + '0*.ARW')\n",
    "train_ids = [int(os.path.basename(train_fn)[0:5]) for train_fn in train_fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/sample/long/00100_00_30s.ARW']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data takes long time to load. Keep them in memory after loaded.                             \n",
    "gt_images = [None] * 6000\n",
    "input_images = {}\n",
    "input_images['300'] = [None] * len(train_ids)\n",
    "input_images['250'] = [None] * len(train_ids)\n",
    "input_images['100'] = [None] * len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerbrown/miniconda3/envs/rose/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: This function is deprecated. Please call randint(0, 0 + 1) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train_id = train_ids[0]\n",
    "in_files = glob.glob(input_dir + '%05d_00*.ARW' % train_id)\n",
    "in_path = in_files[np.random.random_integers(0, len(in_files) - 1)]\n",
    "in_fn = os.path.basename(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_files = glob.glob(gt_dir + '%05d_00*.ARW' % train_id)\n",
    "gt_path = gt_files[0]\n",
    "gt_fn = os.path.basename(gt_path)\n",
    "in_exposure = float(in_fn[9:-5])\n",
    "gt_exposure = float(gt_fn[9:-5])\n",
    "ratio = min(gt_exposure / in_exposure, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "if input_images[str(ratio)[0:3]][ind] == None:\n",
    "    \n",
    "    raw = rawpy.imread(in_path)\n",
    "    input_images[str(ratio)[0:3]][ind] = np.expand_dims(pack_raw(raw), axis=0) * ratio\n",
    "\n",
    "    gt_raw = rawpy.imread(gt_path)\n",
    "    im = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "    gt_images[ind] = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input image: (1, 1424, 2128, 4), gt image: (1, 2848, 4256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"input image: {}, gt image: {}\".format(input_images[str(ratio)[0:3]][ind].shape,gt_images[ind].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop\n",
    "\n",
    "H = input_images[str(ratio)[0:3]][ind].shape[1]\n",
    "W = input_images[str(ratio)[0:3]][ind].shape[2]\n",
    "\n",
    "xx = np.random.randint(0, W - ps)\n",
    "yy = np.random.randint(0, H - ps)\n",
    "input_patch = input_images[str(ratio)[0:3]][ind][:, yy:yy + ps, xx:xx + ps, :]\n",
    "gt_patch = gt_images[ind][:, yy * 2:yy * 2 + ps * 2, xx * 2:xx * 2 + ps * 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024, 1024, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment image during training process\n",
    "\n",
    "if np.random.randint(2, size=1)[0] == 1:  # random flip                                   \n",
    "    input_patch = np.flip(input_patch, axis=1)\n",
    "    gt_patch = np.flip(gt_patch, axis=1)\n",
    "if np.random.randint(2, size=1)[0] == 1:\n",
    "    input_patch = np.flip(input_patch, axis=2)\n",
    "    gt_patch = np.flip(gt_patch, axis=2)\n",
    "if np.random.randint(2, size=1)[0] == 1:  # random transpose                              \n",
    "    input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
    "    gt_patch = np.transpose(gt_patch, (0, 2, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024, 1024, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a minimum value for input patch\n",
    "\n",
    "input_patch = np.minimum(input_patch, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_patch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "It looks like the `y` value is twice the size as `X`. Let's try to mimic\n",
    "that using CIFAR and see if we can get something reasonable. If nothing\n",
    "reasonable happens then we can rewrite their model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = x_train[1,...]\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(im, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = {}\n",
    "gt_images = {}\n",
    "input_images[ind] = np.expand_dims(im, axis=0)\n",
    "gt_images[ind] = np.expand_dims(im, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_images[ind].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_images[ind].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = '300'\n",
    "ps = 8\n",
    "input_images[k] = input_images[ind]\n",
    "gt_images[k] = gt_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop\n",
    "\n",
    "def crop_cifar10_image(input_images, gt_images, k, ps=16):\n",
    "    \"\"\" \n",
    "    The cifar10 dataset images are much smaller than \n",
    "    professional photos taken by IBM. Returns an\n",
    "    input image half the size of the gt_image\n",
    "    \"\"\"\n",
    "\n",
    "    H = input_images[k].shape[1]\n",
    "    W = input_images[k].shape[2]\n",
    "    \n",
    "    print(\"H: {}, W: {}\".format(H, W))\n",
    "    \n",
    "    xx = np.random.randint(0, W - ps)\n",
    "    yy = np.random.randint(0, H - ps)\n",
    "    \n",
    "    print(\"xx: {}, yy: {}\".format(xx, yy))\n",
    "    \n",
    "    input_patch = input_images[k][:,yy:yy + ps, xx:xx + ps, :]\n",
    "    gt_patch = gt_images[k]\n",
    "    \n",
    "    print(\"input_patch: {}\\n   gt_patch: {}\".format(input_patch.shape, gt_patch.shape))\n",
    "\n",
    "\n",
    "\n",
    "#input_patch = input_images[str(ratio)[0:3]][ind][:, yy:yy + ps, xx:xx + ps, :]\n",
    "#gt_patch = gt_images[ind][:, yy * 2:yy * 2 + ps * 2, xx * 2:xx * 2 + ps * 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: 32, W: 32\n",
      "xx: 1, yy: 2\n",
      "input_patch: (1, 16, 16, 3)\n",
      "   gt_patch: (1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "crop_cifar10_image(input_images, gt_images, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
